{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euigdTiKg7DR"
      },
      "source": [
        "# Машинное обучение\n",
        "\n",
        "# Домашнее задание 2. Обучение без учителя, кластеризация.\n",
        "\n",
        "## Общая информация\n",
        "Дата выдачи: 02.10.2025\n",
        "\n",
        "Дедлайн: 16.10.2025 23:59 MSK\n",
        "\n",
        "## Оценивание и штрафы\n",
        "\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи).\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "\n",
        "## О задании\n",
        "\n",
        "В этом задании мы посмотрим на несколько алгоритмов кластеризации и применим их к текстовым данным. Также мы подробно остановимся на тематическом моделировании текстов, задаче обучения представлений и в каком-то смысле поработаем с semi-supervised learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95cdXa4PX8ks"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0xFFFFFFF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr3WXyPBptaN"
      },
      "source": [
        "## Часть 1. Тематическое моделирование текстов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh2yJqxhigf4"
      },
      "source": [
        "В этой части мы познакомимся с одной из самых популярных задач обучения без учителя &mdash; с задачей тематического моделирования текстов. Допустим, нам доступна некоторая коллекция документов без разметки, и мы хотим автоматически выделить несколько тем, которые встречаются в документах, а также присвоить каждому документу одну (или несколько) тем. Фактически, мы будем решать задачу, похожую на кластеризацию текстов: отличие в том, что нас будет интересовать не только разбиение текстов на группы, но и выделение ключевых слов, определяющих каждую тему.\n",
        "\n",
        "Мы будем работать с новостными статьями BBC за 2004-2005 годы. Скачайте данные по [ссылке](https://www.kaggle.com/hgultekin/bbcnewsarchive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMefb5XsixgH"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('bbc-news-data.csv', sep='\\t')\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMiigCjtY0yh"
      },
      "source": [
        "Как вы могли заметить, данные уже содержат разметку по тематике (колонка category). В этой части мы забудем, что она есть, и будем работать только с текстовыми данными. Проведем предобработку текста, состоящую из следующих пунктов:\n",
        "\n",
        "* Объединим заголовок и содержание статьи в одно поле.\n",
        "* Приведем текст к нижнему регистру, разобьем его на токены.\n",
        "* Оставим только буквенные слова (удалив, таким образом, пунктуацию и числа).\n",
        "* Применим лемматизацию.\n",
        "* Удалим стоп-слова.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpSY0M7kbIdl"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk3yw5aNbRgi"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english') + ['ha', 'wa', 'say', 'said'])\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbMsHeS2bV2l"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = list(filter(str.isalpha, word_tokenize(text.lower())))\n",
        "    text = list(lemmatizer.lemmatize(word) for word in text)\n",
        "    text = list(word for word in text if word not in stop_words)\n",
        "    return ' '.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhICemtQbg0o"
      },
      "outputs": [],
      "source": [
        "data['raw_text'] = data.apply(lambda row: row.title + row.content, axis=1)\n",
        "data['text'] = data.apply(lambda row: preprocess(row.raw_text), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0O5ygZPcTkl"
      },
      "source": [
        "Для визуализации частот слов в текстах мы будем использовать [облака тегов](https://en.wikipedia.org/wiki/Tag_cloud)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRo7Q2bXczEZ"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "def draw_wordcloud(texts, max_words=1000, width=1000, height=500):\n",
        "    wordcloud = WordCloud(background_color='white', max_words=max_words,\n",
        "                          width=width, height=height)\n",
        "\n",
        "    joint_texts = ' '.join(list(texts))\n",
        "    wordcloud.generate(joint_texts)\n",
        "    return wordcloud.to_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTnO8HwGdSvA"
      },
      "outputs": [],
      "source": [
        "draw_wordcloud(data.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MoyLGx-dcjF"
      },
      "source": [
        "**Задание 1.1 (1 балл).** Обучите алгоритм K-Means на tf-idf представлениях текстов. При обучении tf-idf векторайзера рекомендуется отбрасывать редко встречающиеся слова, а также воздержитесь от использования N-грамм. Возьмите не очень большое число кластеров, чтобы было удобно интерпретировать получившиеся темы (например, `n_clusters` = 8). Постройте облака тегов для текстов из разных кластеров. Получились ли темы интерпретируемыми? Попробуйте озаглавить каждую тему.\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr65aXYRU7f2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b41ggvxRU_Oc"
      },
      "source": [
        "**Задание 1.2 (1 балл).** Попробуем другой способ выделить ключевые слова для каждой темы. Помимо непосредственного разбиения объектов алгоритм K-Means получает центр каждого кластера. Попробуйте взять центры кластеров и посмотреть на слова, для которых значения соответствующих им признаков максимальны. Согласуются ли полученные слова с облаками тегов из прошлого задания?\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYm-9i2bX7tJ"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjiogHYuYB0p"
      },
      "source": [
        "**Задание 1.3 (2 балла).** Посмотрим на кластеризацию для текстовых данных (в качестве признакого описания снова используем tf-idf). Получите три разбиения на кластеры с помощью алгоритмов K-Means, DBSCAN и спектральной кластеризации (на этот раз воспользуйтесь реализацией из `sklearn`). Для K-Means и спектральной кластеризации возьмите одинаковое небольшое число кластеров, подберите параметр `eps` метода DBSCAN так, чтобы получить приблизительно такое же число кластеров.\n",
        "\n",
        "Далее, обучите двухмерные t-SNE представления над tf-idf признаками текстов. Визуализируйте эти представления для каждого алгоритма, раскрасив каждый кластер своим цветом. Лучше всего расположить визуализации на одном графике на трех разных сабплотах. Не забудьте, что DBSCAN помечает некоторые точки как шумовые (можно раскрасить их в отдельный цвет)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0fA0yEOYg_e"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZo8daJrcyTR"
      },
      "source": [
        "Прокомментируйте получившиеся результаты. Какой баланс кластеров получился у разных методов? Соотносятся ли визуализации для текстов с визуализациями для географических данных?\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7zArHv6dsVg"
      },
      "source": [
        "**Задание 1.4 (2 балла).** Обучите модель латентного размещения Дирихле. Не забудьте, что она работает с мешком слов, а не с tf-idf признаками. Придумайте, как превратить распределение тем для текста в номер его кластера. Возьмите параметр `n_components` в 2-3 раза больше, чем число кластеров для K-Means. Получились ли темы более узкими от такого нововведения? Постройте облака тегов для нескольких наиболее удачных тем.\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGw_tnc_dwgT"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfWNOqFZii3J"
      },
      "source": [
        "## Часть 2. Transfer learning для задачи классификации текстов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4clP98BXGLax"
      },
      "source": [
        "**Задание 2.1 (0.5 балла).** Вспомним, что у нас есть разметка для тематик статей. Попробуем обучить классификатор поверх unsupervised-представлений для текстов. Рассмотрите три модели:\n",
        "\n",
        "* Логистическая регрессия на tf-idf признаках\n",
        "* K-Means на tf-idf признаках + логистическая регрессия на расстояниях до центров кластеров\n",
        "* Латентное размещение Дирихле + логистическая регрессия на вероятностях тем\n",
        "\n",
        "Разделите выборку на обучающую и тестовую, замерьте accuracy на обоих выборках для всех трех моделей. Параметры всех моделей возьмите равными значениям по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7KiHqfkhO_R"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsbJHnR8gzHX"
      },
      "source": [
        "У какой модели получилось лучшее качество? С чем это связано?\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18vaNs6XGScR"
      },
      "source": [
        "**Задание 2.2 (1.5 балла).** Теперь просимулируем ситуацию слабой разметки, которая часто встречается в реальных данных. Разделим обучающую выборку в пропорции 5:65:30. Будем называть части, соответственно, размеченный трейн, неразмеченный трейн и валидация.\n",
        "\n",
        "Все unsupervised-алгоритмы (векторайзеры и алгоритмы кластеризации) запускайте на всем трейне целиком (размеченном и неразмеченном, суммарно 70%), а итоговый классификатор обучайте только на размеченном трейне (5%). Подберите гиперпараметры моделей по качеству на валидации (30%), а затем оцените качество на тестовой выборке (которая осталась от прошлого задания). Не скромничайте при подборе числа кластеров, сейчас нас интересует не интерпретируемое разбиение выборки, а итоговое качество классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n45ZJCDAGTQG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMP7BslkkYAl"
      },
      "source": [
        "Как изменились результаты по сравнению с обучением на полной разметке? Сделайте выводы.\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkAs4eBx8CXr"
      },
      "source": [
        "**Задание 3 (1 балл)**. Разберитесь с semi-supervised методами, которые реализованы в `sklearn` и примените их к заданию 3.2. Получилось ли добиться лучшего качества? Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHTs3_ssKVG7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOI6tcLoKVoS"
      },
      "source": [
        "**Задание 4 (1 балл)**. Есть такая метрика [BCubed](https://www.researchgate.net/profile/Julio-Gonzalo-2/publication/225548032_Amigo_E_Gonzalo_J_Artiles_J_et_alA_comparison_of_extrinsic_clustering_evaluation_metrics_based_on_formal_constraints_Inform_Retriev_12461-486/links/0c96052138dbb99740000000/Amigo-E-Gonzalo-J-Artiles-J-et-alA-comparison-of-extrinsic-clustering-evaluation-metrics-based-on-formal-constraints-Inform-Retriev-12461-486.pdf) хорошо подходит для сравнения алгоритмов кластеризации, если нам известно настоящее разделение на кластеры (gold standard). Реализуйте подсчет метрики BCubed и сравните несколько алгоритмов кластеризации на текстовых данных из основного задания. В качестве gold standard используйте разметку category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQtZe7Ty847i"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
